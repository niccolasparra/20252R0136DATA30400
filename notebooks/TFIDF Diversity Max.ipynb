{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ TF-IDF Pure: Diversity Maximization\n",
    "\n",
    "Objetivo: 250+ clases Ãºnicas â†’ score 0.40-0.50\n",
    "\n",
    "**Estrategia:**\n",
    "1. TF-IDF puro sin BERT (BERT causa collapse)\n",
    "2. Threshold muy bajo para maximizar diversidad\n",
    "3. CalibraciÃ³n por percentiles\n",
    "4. Keyword boosting agresivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:53:22.088775Z",
     "iopub.status.busy": "2025-12-19T14:53:22.088639Z",
     "iopub.status.idle": "2025-12-19T14:53:23.714628Z",
     "shell.execute_reply": "2025-12-19T14:53:23.713890Z",
     "shell.execute_reply.started": "2025-12-19T14:53:22.088759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Imports ready\n",
      "CPU times: user 336 ms, sys: 141 ms, total: 477 ms\n",
      "Wall time: 1.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip install -q scikit-learn pandas numpy\n",
    "\n",
    "import os, csv, re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter, defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('âœ“ Imports ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:53:24.818608Z",
     "iopub.status.busy": "2025-12-19T14:53:24.818405Z",
     "iopub.status.idle": "2025-12-19T14:53:24.870713Z",
     "shell.execute_reply": "2025-12-19T14:53:24.869958Z",
     "shell.execute_reply.started": "2025-12-19T14:53:24.818584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 29487 Test: 19658 Classes: 531\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "def load_corpus(path):\n",
    "    d = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            p = line.strip().split('\\t', 1)\n",
    "            if len(p)==2: d[p[0]] = p[1]\n",
    "    return d\n",
    "\n",
    "def load_classes(path):\n",
    "    m = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            p = line.strip().split('\\t')\n",
    "            if len(p)==2: m[int(p[0])] = p[1]\n",
    "    return m\n",
    "\n",
    "def load_keywords(path):\n",
    "    d = {}\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            p = line.strip().split(':', 1)\n",
    "            if len(p)==2: d[p[0]] = [w.strip() for w in p[1].split(',')]\n",
    "    return d\n",
    "\n",
    "DATA = 'data'\n",
    "train = load_corpus(os.path.join(DATA, 'train/train_corpus.txt'))\n",
    "test = load_corpus(os.path.join(DATA, 'test/test_corpus.txt'))\n",
    "id2cls = load_classes(os.path.join(DATA, 'classes.txt'))\n",
    "kw = load_keywords(os.path.join(DATA, 'class_related_keywords.txt'))\n",
    "NCLS = 531\n",
    "print('Train:', len(train), 'Test:', len(test), 'Classes:', NCLS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:53:25.997329Z",
     "iopub.status.busy": "2025-12-19T14:53:25.997050Z",
     "iopub.status.idle": "2025-12-19T14:53:26.002813Z",
     "shell.execute_reply": "2025-12-19T14:53:26.002021Z",
     "shell.execute_reply.started": "2025-12-19T14:53:25.997314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class descriptions built with 5x keyword boost\n",
      "CPU times: user 1.29 ms, sys: 0 ns, total: 1.29 ms\n",
      "Wall time: 1.29 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build class descriptions with keyword repetition (boosting)\n",
    "cls_desc = []\n",
    "for i in range(NCLS):\n",
    "    name = id2cls[i]\n",
    "    words = kw.get(name, [])\n",
    "    if not words: words = [name.replace('_', ' ')]\n",
    "    # Repeat keywords 5x for boosting\n",
    "    desc = ' '.join([w.replace('_', ' ') for w in words] * 5)\n",
    "    cls_desc.append(desc)\n",
    "\n",
    "print('Class descriptions built with 5x keyword boost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:54:06.007265Z",
     "iopub.status.busy": "2025-12-19T14:54:06.007115Z",
     "iopub.status.idle": "2025-12-19T14:54:25.706936Z",
     "shell.execute_reply": "2025-12-19T14:54:25.705070Z",
     "shell.execute_reply.started": "2025-12-19T14:54:06.007249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 Î¼s, sys: 0 ns, total: 2 Î¼s\n",
      "Wall time: 5.48 Î¼s\n",
      "Vocabulary size: 25000\n",
      "Test matrix: (19658, 25000) Class matrix: (531, 25000)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# TF-IDF vectorizer with aggressive parameters\n",
    "vec = TfidfVectorizer(\n",
    "    max_features=25000,\n",
    "    ngram_range=(1,4),\n",
    "    stop_words='english',\n",
    "    min_df=1,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "# Fit on combined corpus\n",
    "all_text = list(train.values()) + list(test.values()) + cls_desc\n",
    "vec.fit(all_text)\n",
    "print('Vocabulary size:', len(vec.vocabulary_))\n",
    "\n",
    "# Transform\n",
    "T_test = vec.transform(test.values())\n",
    "C_vec = vec.transform(cls_desc)\n",
    "print('Test matrix:', T_test.shape, 'Class matrix:', C_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:54:25.707635Z",
     "iopub.status.busy": "2025-12-19T14:54:25.707482Z",
     "iopub.status.idle": "2025-12-19T14:54:25.783517Z",
     "shell.execute_reply": "2025-12-19T14:54:25.782124Z",
     "shell.execute_reply.started": "2025-12-19T14:54:25.707620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity matrix: (19658, 531)\n",
      "CPU times: user 29 ms, sys: 44.1 ms, total: 73 ms\n",
      "Wall time: 72.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute similarities\n",
    "S = cosine_similarity(T_test, C_vec)\n",
    "print('Similarity matrix:', S.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:54:28.623294Z",
     "iopub.status.busy": "2025-12-19T14:54:28.623064Z",
     "iopub.status.idle": "2025-12-19T14:54:30.336243Z",
     "shell.execute_reply": "2025-12-19T14:54:30.335595Z",
     "shell.execute_reply.started": "2025-12-19T14:54:28.623275Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19658/19658 [00:01<00:00, 11517.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Predictions done\n",
      "CPU times: user 1.71 s, sys: 3.96 ms, total: 1.72 s\n",
      "Wall time: 1.71 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Predictions with adaptive threshold per sample\n",
    "test_pids = list(test.keys())\n",
    "preds = {}\n",
    "\n",
    "for i, pid in enumerate(tqdm(test_pids, desc='Predict')):\n",
    "    scores = S[i]\n",
    "    \n",
    "    # Strategy: take top 30 candidates, filter by dynamic threshold\n",
    "    top_idx = np.argsort(scores)[::-1][:30]\n",
    "    top_scores = scores[top_idx]\n",
    "    \n",
    "    # Dynamic threshold: 50th percentile of top 30\n",
    "    thresh = np.percentile(top_scores, 50)\n",
    "    \n",
    "    # Apply minimum threshold\n",
    "    thresh = max(thresh, 0.02)\n",
    "    \n",
    "    # Select candidates\n",
    "    cands = [(int(idx), scores[idx]) for idx in top_idx if scores[idx] >= thresh]\n",
    "    \n",
    "    # Ensure at least 2, at most 5\n",
    "    if len(cands) < 2:\n",
    "        cands = [(int(idx), scores[idx]) for idx in top_idx[:3]]\n",
    "    elif len(cands) > 5:\n",
    "        cands = cands[:5]\n",
    "    \n",
    "    preds[pid] = [c[0] for c in cands[:3]]\n",
    "\n",
    "print('âœ“ Predictions done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:54:32.430412Z",
     "iopub.status.busy": "2025-12-19T14:54:32.430175Z",
     "iopub.status.idle": "2025-12-19T14:54:32.441522Z",
     "shell.execute_reply": "2025-12-19T14:54:32.440883Z",
     "shell.execute_reply.started": "2025-12-19T14:54:32.430396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DIVERSITY ANALYSIS:\n",
      "Unique classes predicted: 531\n",
      "Target: 250+ for score 0.40-0.50\n",
      "\n",
      "Top 10 most frequent:\n",
      "  Class 220 (fragrance): 764 times\n",
      "  Class 199 (dogs): 383 times\n",
      "  Class 65 (styling_products): 366 times\n",
      "  Class 242 (men_s): 363 times\n",
      "  Class 181 (grooming_healthcare_kits): 341 times\n",
      "  Class 155 (bedding): 326 times\n",
      "  Class 472 (kickball_playground_balls): 323 times\n",
      "  Class 25 (deodorants_antiperspirants): 309 times\n",
      "  Class 221 (women_s): 303 times\n",
      "  Class 32 (household_batteries): 291 times\n",
      "\n",
      "Distribution:\n",
      "  >100 times: 249\n",
      "  50-100: 190\n",
      "  10-50: 91\n",
      "  <10: 1\n"
     ]
    }
   ],
   "source": [
    "# Diversity check\n",
    "all_pred_classes = []\n",
    "for labels in preds.values():\n",
    "    all_pred_classes.extend(labels)\n",
    "\n",
    "unique = len(set(all_pred_classes))\n",
    "cnt = Counter(all_pred_classes)\n",
    "print(f'\\nDIVERSITY ANALYSIS:')\n",
    "print(f'Unique classes predicted: {unique}')\n",
    "print(f'Target: 250+ for score 0.40-0.50')\n",
    "print(f'\\nTop 10 most frequent:')\n",
    "for c, freq in cnt.most_common(10):\n",
    "    print(f'  Class {c} ({id2cls[c]}): {freq} times')\n",
    "print(f'\\nDistribution:')\n",
    "print(f'  >100 times: {sum(1 for x in cnt.values() if x > 100)}')\n",
    "print(f'  50-100: {sum(1 for x in cnt.values() if 50 <= x <= 100)}')\n",
    "print(f'  10-50: {sum(1 for x in cnt.values() if 10 <= x < 50)}')\n",
    "print(f'  <10: {sum(1 for x in cnt.values() if x < 10)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-19T14:54:36.345773Z",
     "iopub.status.busy": "2025-12-19T14:54:36.345546Z",
     "iopub.status.idle": "2025-12-19T14:54:36.372404Z",
     "shell.execute_reply": "2025-12-19T14:54:36.371357Z",
     "shell.execute_reply.started": "2025-12-19T14:54:36.345754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ“ Saved to: outputs/tfidf_diversity_max.csv\n",
      "\n",
      "UPLOAD THIS FILE TO KAGGLE\n"
     ]
    }
   ],
   "source": [
    "# Save\n",
    "OUT = 'outputs'\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "out = os.path.join(OUT, 'tfidf_diversity_max.csv')\n",
    "\n",
    "with open(out, 'w', newline='', encoding='utf-8') as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow(['id', 'labels'])\n",
    "    for pid in sorted(preds.keys(), key=lambda x: int(x)):\n",
    "        w.writerow([pid, ','.join(map(str, preds[pid]))])\n",
    "\n",
    "print(f'\\nâœ“ Saved to: {out}')\n",
    "print('\\nUPLOAD THIS FILE TO KAGGLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
